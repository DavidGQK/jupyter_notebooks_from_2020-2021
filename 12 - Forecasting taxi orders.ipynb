{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Clear Taxi company has collected historical data on taxi orders at airports.\n",
    "<br>In order to attract more drivers during the peak period, you need to predict the number of taxi orders for the next hour.\n",
    "<br>It is necessary to build a model for such a prediction.\n",
    "<br>The value of the RMSE metric on the test sample should not exceed 48."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is in the file `/datasets/taxi.csv`\n",
    "<br>The number of orders is in the `num_orders` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the data and resample it one hour at a time.\n",
    "2. Analyze the data.\n",
    "3. Train different models with different hyperparameters (make a test sample of 10% of the original data).\n",
    "4. Check the data on the test sample and draw conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and resampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pd.set_option('display.max_row',100)\n",
    "pd.set_option('display.max_columns',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/taxi.csv', index_col=[0], parse_dates=[0],sep=',')\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ресемплируем данные по одному часу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.resample('1H').sum()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the indices for monotonicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.is_monotonic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of rows and number of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['num_orders'].count()\n",
    "b = df['num_orders'].isna().sum()\n",
    "print(a)\n",
    "print(b)\n",
    "100*b/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "sns.lineplot(x=df.index,y=df['num_orders'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взглянем в разрезе 21-го дня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_7 = df['2018-03-01':'2018-03-07']\n",
    "df_8_14 = df['2018-03-08':'2018-03-14']\n",
    "df_15_21 = df['2018-03-15':'2018-03-21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(20, 10), sharey=True)\n",
    "fig.suptitle('In the context of 21 days')\n",
    "\n",
    "sns.lineplot(ax=axes[0], x=df_1_7.index,y=df_1_7['num_orders'])\n",
    "axes[0].set_title('1-7')\n",
    "axes[0].set_xlabel('')\n",
    "\n",
    "sns.lineplot(ax=axes[1], x=df_8_14.index,y=df_8_14['num_orders'])\n",
    "axes[1].set_title('8-14')\n",
    "axes[1].set_xlabel('')\n",
    "\n",
    "sns.lineplot(ax=axes[2], x=df_15_21.index,y=df_15_21['num_orders'])\n",
    "axes[2].set_title('15-21')\n",
    "axes[2].set_xlabel('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the same graphs, but in the next months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_7 = df['2018-04-01':'2018-04-07']\n",
    "df_8_14 = df['2018-04-08':'2018-04-14']\n",
    "df_15_21 = df['2018-04-15':'2018-04-21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(20, 10), sharey=True)\n",
    "fig.suptitle('In the context of 21 days')\n",
    "\n",
    "sns.lineplot(ax=axes[0], x=df_1_7.index,y=df_1_7['num_orders'])\n",
    "axes[0].set_title('1-7')\n",
    "axes[0].set_xlabel('')\n",
    "\n",
    "sns.lineplot(ax=axes[1], x=df_8_14.index,y=df_8_14['num_orders'])\n",
    "axes[1].set_title('8-14')\n",
    "axes[1].set_xlabel('')\n",
    "\n",
    "sns.lineplot(ax=axes[2], x=df_15_21.index,y=df_15_21['num_orders'])\n",
    "axes[2].set_title('15-21')\n",
    "axes[2].set_xlabel('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the workload schedules during the week are similar.\n",
    "<br>We continue to consider in more detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a graph of trends and seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed = seasonal_decompose(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(311)\n",
    "\n",
    "decomposed.trend.plot(ax=plt.gca())\n",
    "plt.title('Trend')\n",
    "\n",
    "plt.subplot(312)\n",
    "decomposed.seasonal.plot(ax=plt.gca()) \n",
    "plt.title('Seasonality')\n",
    "\n",
    "plt.subplot(313)\n",
    "decomposed.resid.plot(ax=plt.gca()) \n",
    "plt.title('Residuals')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a trend to increase the number of orders per day, orders do not depend on seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(311)\n",
    "\n",
    "decomposed.trend['2018-03-01':'2018-04-01'].plot(ax=plt.gca())\n",
    "plt.title('Trend')\n",
    "\n",
    "plt.subplot(312)\n",
    "decomposed.seasonal['2018-03-01':'2018-04-01'].plot(ax=plt.gca()) \n",
    "plt.title('Seasonality')\n",
    "\n",
    "plt.subplot(313)\n",
    "decomposed.resid['2018-03-01':'2018-04-01'].plot(ax=plt.gca()) \n",
    "plt.title('Residuals')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been analyzed.\n",
    "<br>Load schedules are similar during the week.\n",
    "<br>There is a trend to increase the number of orders per day over time, the number of orders does not depend on the season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building forecast models for orders for the next hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that adds new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(data, max_lag, rolling_mean_size):\n",
    "    data['month'] = data.index.month\n",
    "    data['day'] = data.index.day\n",
    "    data['dayofweek'] = data.index.dayofweek\n",
    "    \n",
    "    for lag in range(1, max_lag + 1):\n",
    "        data['lag_{}'.format(lag)] = data['num_orders'].shift(lag)\n",
    "\n",
    "    data['rolling_mean'] = data['num_orders'].shift().rolling(rolling_mean_size).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = copy.deepcopy(df)\n",
    "make_features(data, 20, 2)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the sample into sets with features and a target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(['num_orders'],axis=1)\n",
    "target = data['num_orders']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break the sets into train and test in the ratio of `9:1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_train, features_test = train_test_split(features, test_size=0.1, shuffle=False)\n",
    "# target_train, target_test = train_test_split(target, test_size=0.1, shuffle=False)\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.1, shuffle=False)\n",
    "\n",
    "print(features.shape)\n",
    "print(target.shape)\n",
    "print()\n",
    "\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print()\n",
    "\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_l_r = LinearRegression()\n",
    "model_l_r.fit(features_train, target_train)\n",
    "predictions_train = model_l_r.predict(features_train)\n",
    "rmse_train = mean_squared_error(predictions_train, target_train) ** 0.5\n",
    "print('RMSE of a linear model on a train set:', rmse_train)\n",
    "\n",
    "predictions_test = model_l_r.predict(features_test)\n",
    "rmse_test = mean_squared_error(predictions_test, target_test) ** 0.5\n",
    "print('RMSE of a linear model on a test set:', rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {'max_depth': range(1,100)}\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "dtr = GridSearchCV(estimator=DecisionTreeRegressor(random_state=12345), param_grid=param_grid, cv=tscv)\n",
    "dtr.fit(features_train, target_train)\n",
    "dtr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_train = dtr.predict(features_train)\n",
    "rmse_train = mean_squared_error(predictions_train, target_train) ** 0.5\n",
    "print('RMSE of the decision tree on the train set:', rmse_train)\n",
    "\n",
    "predictions_test = dtr.predict(features_test)\n",
    "rmse_test = mean_squared_error(predictions_test, target_test) ** 0.5\n",
    "print('RMSE of the decision tree on the test set:', rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {'n_estimators': range(1,50,2), 'max_depth': range(1,20,2)}\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "rfr = GridSearchCV(estimator=RandomForestRegressor(random_state=12345), param_grid=param_grid, cv=tscv)\n",
    "rfr.fit(features_train, target_train)\n",
    "rfr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = rfr.predict(features_train)\n",
    "rmse_train = mean_squared_error(predictions_train, target_train) ** 0.5\n",
    "print('RMSE of the random forest on the train set:', rmse_train)\n",
    "\n",
    "predictions_test = rfr.predict(features_test)\n",
    "rmse_test = mean_squared_error(predictions_test, target_test) ** 0.5\n",
    "print('RMSE of a random forest on a test set:', rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.005,\n",
    "    'verbose': 0,\n",
    "    \"max_depth\": 20,\n",
    "    \"num_iterations\": 100000,\n",
    "    \"n_estimators\": 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbm = lgb.LGBMRegressor(**hyper_params)\n",
    "gbm.fit(features_train, target_train, verbose=0)\n",
    "gbm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = gbm.predict(features_train)\n",
    "rmse_train = mean_squared_error(predictions_train, target_train) ** 0.5\n",
    "print('RMSE LightGBM on the train set:', rmse_train)\n",
    "\n",
    "predictions_test = gbm.predict(features_test)\n",
    "rmse_test = mean_squared_error(predictions_test, target_test) ** 0.5\n",
    "print('RMSE LightGBM on test set:', rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the importance of LightGBM factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(gbm.feature_importances_,\n",
    "                                   index = features.columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the results on the test dataset, LightGBM takes first place, and random forest is in second place.\n",
    "<br>It should also be taken into account that LightGBM works, in this case, 3 times faster than random forest.\n",
    "<br>It is worth noting that in order to get `rmse` less than 48, several iterations were carried out with the regulation of not only the hyperparameters of the models, but also, what is especially important, with the regulation of the number of differences in the time series and the size of the averaging window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
