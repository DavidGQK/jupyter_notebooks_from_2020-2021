{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to prepare a prototype of a machine learning model for the Zifry company.\n",
    "<br> The company develops solutions for the efficient operation of industrial enterprises.\n",
    "\n",
    "The model should predict the recovery rate of gold from gold ore.\n",
    "<br> Data with extraction and treatment parameters are available.\n",
    "\n",
    "The model will help optimize production so as not to launch an enterprise with unprofitable characteristics.\n",
    "\n",
    "Necessary:\n",
    "\n",
    "- Prepare data;\n",
    "- Conduct exploratory data analysis;\n",
    "- Build and train the model.\n",
    "\n",
    "Gold from ore is obtained in the following way:\n",
    "\n",
    "When the mined ore undergoes primary processing, a crushed mixture is obtained.\n",
    "<br> It is sent for `flotation (enrichment)` and `two-stage cleaning`:\n",
    "\n",
    "1. Flotation\n",
    "A mixture of gold-bearing ore is fed into the flotation plant. After enrichment, a rough concentrate and “dump tails” are obtained, that is, product residues with a low concentration of valuable metals.\n",
    "The stability of this process is affected by the unstable and non-optimal physical and chemical state of the flotation pulp (a mixture of solid particles and liquid).\n",
    "2. Cleaning\n",
    "The crude concentrate goes through two purifications. The output is the final concentrate and new final tailings.\n",
    "\n",
    "You need to predict two quantities at once:\n",
    "- rough concentrate enrichment efficiency `rougher.output.recovery`;\n",
    "- efficiency of enrichment of the final concentrate `final.output.recovery`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is in three files:\n",
    "\n",
    "- gold_recovery_train.csv - train sample;\n",
    "- gold_recovery_test.csv - test sample;\n",
    "- gold_recovery_full.csv - initial data.\n",
    "\n",
    "The data is indexed by the date and time the information was received (the date attribute). Parameters adjacent in time are often similar.\n",
    "\n",
    "Some parameters are not available because they are measured and/or calculated much later. Because of this, the test set lacks some features that may be in the train set. Also, there are no target features in the test set.\n",
    "\n",
    "The initial dataset contains the train and test sets with all features.\n",
    "\n",
    "This is raw data: it has just been unloaded from storage. Before proceeding with the construction of the model, it is necessary to check them for correctness.\n",
    "\n",
    "\n",
    "Technological process:\n",
    "- Rougher feed - feedstock\n",
    "- Rougher additions (or reagent additions) - flotation reagents: Xanthate, Sulphate, Depressant\n",
    "- Xanthate ** - xanthate (promoter, or flotation activator);\n",
    "- Sulphate - sulfate (in this production, sodium sulfide);\n",
    "- Depressant - depressant (sodium silicate).\n",
    "- Rougher process (English \"rough process\") - flotation\n",
    "- Rougher tails\n",
    "- Float banks - flotation unit\n",
    "- Cleaner process - cleaning\n",
    "- Rougher Au - rough gold concentrate\n",
    "- Final Au - final gold concentrate\n",
    "\n",
    "Stage parameters\n",
    "- air amount — air volume\n",
    "- fluid levels - fluid level\n",
    "- feed size - feed granule size\n",
    "- feed rate - feed rate\n",
    "\n",
    "\n",
    "The name of the features is: `[stage].[parameter_type].[parameter_name]`\n",
    "Example: `rougher.input.feed_ag`\n",
    "\n",
    "Possible values ​​for the `[stage]` block:\n",
    "- rougher - flotation\n",
    "- primary_cleaner - primary cleaning\n",
    "- secondary_cleaner - secondary cleaning\n",
    "- final - final characteristics\n",
    "\n",
    "Possible values ​​for the `[parameter_type]` block:\n",
    "- input — raw material parameters\n",
    "- output — product parameters\n",
    "- state — parameters characterizing the current state of the stage\n",
    "- calculation - calculated characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare data\n",
    "- 1.1. Open files and examine them.\n",
    "- 1.2. Verify that the enrichment efficiency is calculated correctly. Calculate it on the train sample for the feature `rougher.output.recovery`. Find `MAE` between calculation and feature value. Describe findings.\n",
    "- 1.3. Analyze features that are not available in the test sample. What are these parameters? What type are they?\n",
    "- 1.4. Perform data preprocessing.\n",
    "2. Analyze the data\n",
    "- 2.1. See how the concentration of metals (Au, Ag, Pb) changes at different stages of purification. Describe findings.\n",
    "- 2.2. Compare the size distributions of raw material granules on the train and test samples. If the distributions are very different from each other, the estimation of the model will be wrong.\n",
    "- 2.3. Investigate the total concentration of all substances at different stages: in raw materials, in roughing and final concentrates. Are there any anomalous values ​​in the total distribution or not? If they are, should they be removed from both samples? Describe findings and remove anomalies.\n",
    "3. Build the model\n",
    "- 3.1. Write a function to calculate the final `sMAPE`.\n",
    "- 3.2. Train different models and evaluate their quality by cross-validation. Choose the best model and test it on a test set. Describe findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data files, study general information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.figure_factory as ff\n",
    "from IPython.display import display\n",
    "from IPython.display import display_html\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from scipy import stats as st\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('datasets/gold_recovery_train.csv', sep=',')\n",
    "df_test = pd.read_csv('datasets/gold_recovery_test.csv', sep=',')\n",
    "df_full = pd.read_csv('datasets/gold_recovery_full.csv', sep=',')\n",
    "\n",
    "# df_train = pd.read_csv('/datasets/gold_recovery_train.csv', sep=',')\n",
    "# df_test = pd.read_csv('/datasets/gold_recovery_test.csv', sep=',')\n",
    "# df_full = pd.read_csv('/datasets/gold_recovery_full.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)\n",
    "\n",
    "#display_side_by_side(df_train.head(),df_test.head(),df_full.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification of enrichment efficiency calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for calculating enrichment efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recovery(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    C — share of gold in concentrate after flotation/refining;\n",
    "    F — share of gold in raw material/concentrate before flotation/refining;\n",
    "    T — share of gold in final tailings after flotation/cleaning.\n",
    "    \"\"\"\n",
    "    C = df['rougher.output.concentrate_au']\n",
    "    F = df['rougher.input.feed_au']\n",
    "    T = df['rougher.output.tail_au']\n",
    "    \n",
    "    return 100 * C * (F - T) / (F * (C - T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the enrichment efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_my = df_train['rougher.output.recovery']\n",
    "my = recovery(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if there are missing or infinite values in the received samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.any(np.isnan(not_my)))\n",
    "print(np.all(np.isfinite(not_my)))\n",
    "print()\n",
    "print(np.any(np.isnan(my)))\n",
    "print(np.all(np.isfinite(my)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new dataframe, in which we will enter two arrays so that we can correctly remove the gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame()\n",
    "table['not_my'] = not_my\n",
    "table['my'] = my\n",
    "table = table.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.any(np.isnan(table)))\n",
    "print(np.all(np.isfinite(table)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = mean_absolute_error(table['not_my'], table['my'])\n",
    "print('MAE:', MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAE value is very close to zero, which means that the data and the calculation formula are interpreted and understood by me correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of features of the train set that are not available in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find features that are missing in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_train = pd.DataFrame(df_train.columns.to_list())\n",
    "col_test = pd.DataFrame(df_test.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_concat = pd.concat([col_train,col_test]).drop_duplicates(keep=False)\n",
    "col_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what date the data in the test set is dated and compare it with the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train['date'].sort_values())\n",
    "display(df_test['date'].sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_train = pd.DataFrame(df_train['date'].to_list())\n",
    "date_test = pd.DataFrame(df_test['date'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_concat = pd.concat([date_train,date_test]).drop_duplicates(keep=False)\n",
    "date_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most likely, all features that are not available in the test set are computable.\n",
    "<br>Since all signs refer either to product parameters or design characteristics.\n",
    "<br>The dates in the test sample completely coincide with the dates in the train sample, which once again shows that the unavailable features are computable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change in the concentration of metals (Au, Ag, Pb) at different stages of purification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the concentrations of Au, Ag, Pb at various stages in the context of two days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hours = 50\n",
    "figsize = (10,10)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "\n",
    "plt.plot(df_train['rougher.output.concentrate_au'][:hours], label='au rougher')\n",
    "plt.plot(df_train['primary_cleaner.output.concentrate_au'][:hours], label='au primary_cleaner')\n",
    "plt.plot(df_train['final.output.concentrate_au'][:hours], label='au final')\n",
    "\n",
    "legend = plt.legend(loc='lower left', shadow=False, fontsize='medium')\n",
    "plt.title('Au')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "\n",
    "plt.plot(df_train['rougher.output.concentrate_ag'][:hours], label='ag rougher')\n",
    "plt.plot(df_train['primary_cleaner.output.concentrate_ag'][:hours], label='ag primary_cleaner')\n",
    "plt.plot(df_train['final.output.concentrate_ag'][:hours], label='ag final')\n",
    "\n",
    "legend = plt.legend(loc='lower left', shadow=False, fontsize='medium')\n",
    "plt.title('Ag')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "\n",
    "plt.plot(df_train['rougher.output.concentrate_pb'][:hours], label='pb rougher')\n",
    "plt.plot(df_train['primary_cleaner.output.concentrate_pb'][:hours], label='pb primary_cleaner')\n",
    "plt.plot(df_train['final.output.concentrate_pb'][:hours], label='pb final')\n",
    "\n",
    "legend = plt.legend(loc='lower left', shadow=False, fontsize='medium')\n",
    "plt.title('Pb')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concentration of gold increases with each stage of purification, which is logical.\n",
    "<br> The concentration of silver decreases with each stage, which is also logical.\n",
    "<br> But the concentration of lead is growing. This is probably due to the technological process of processing and lead is not yet removed at these stages.\n",
    "<br> Abnormal values are also visible, which may be associated with the technological process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the size distribution of raw material granules on the train and test samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rougher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the equality of the mean of two general populations for their samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = st.ttest_ind(df_train['rougher.input.feed_size'].dropna(), df_test['rougher.input.feed_size'].dropna(), equal_var=False)\n",
    "print('p-value:',results.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions in the primary_cleaner stage do not differ much from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# hist_data = [df_train['rougher.input.feed_size'].dropna(), df_test['rougher.input.feed_size'].dropna()]\n",
    "# group_labels = ['train', 'test']\n",
    "\n",
    "# fig = ff.create_distplot(hist_data, group_labels, bin_size=0.2)\n",
    "# fig.show()\n",
    "\n",
    "sns.distplot(df_train['rougher.input.feed_size'].dropna(), label='train')\n",
    "sns.distplot(df_test['rougher.input.feed_size'].dropna(), label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions at the rougher stage do not differ much from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary_cleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the equality of the mean of two general populations for their samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = st.ttest_ind(df_train['primary_cleaner.input.feed_size'], df_test['primary_cleaner.input.feed_size'], equal_var=False)\n",
    "print('p-value:',results.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_data = [df_train['primary_cleaner.input.feed_size'], df_test['primary_cleaner.input.feed_size']]\n",
    "# group_labels = ['train', 'test']\n",
    "\n",
    "# fig = ff.create_distplot(hist_data, group_labels, bin_size=0.2)\n",
    "# fig.show()\n",
    "\n",
    "sns.distplot(df_train['primary_cleaner.input.feed_size'].dropna(), label='train')\n",
    "sns.distplot(df_test['primary_cleaner.input.feed_size'].dropna(), label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions in the primary_cleaner stage do not differ much from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study of the total concentration of all substances at different stages: in raw materials, in roughing and final concentrates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sum_rougher'] = df_train['rougher.output.concentrate_ag'] + df_train['rougher.output.concentrate_pb'] + \\\n",
    "                          df_train['rougher.output.concentrate_sol'] + df_train['rougher.output.concentrate_au']\n",
    "\n",
    "df_train['sum_primary'] = df_train['primary_cleaner.output.concentrate_ag'] + df_train['primary_cleaner.output.concentrate_pb'] + \\\n",
    "                          df_train['primary_cleaner.output.concentrate_sol'] + df_train['primary_cleaner.output.concentrate_au']\n",
    "\n",
    "df_train['sum_final'] = df_train['final.output.concentrate_ag'] + df_train['final.output.concentrate_pb'] + \\\n",
    "                        df_train['final.output.concentrate_sol'] + df_train['final.output.concentrate_au']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = 200\n",
    "figsize = (5,5)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "\n",
    "plt.plot(df_train['sum_rougher'][:hours], label='sum rougher')\n",
    "plt.plot(df_train['sum_primary'][:hours], label='sum primary_cleaner')\n",
    "plt.plot(df_train['sum_final'][:hours], label='sum final')\n",
    "\n",
    "legend = plt.legend(loc='lower left', shadow=False, fontsize='small')\n",
    "plt.title('Sum concentrations')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "sns.displot(df_train['sum_rougher'], kde=True, height=5, aspect=1)\n",
    "sns.displot(df_train['sum_primary'], kde=True, height=5, aspect=1)\n",
    "sns.displot(df_train['sum_final'], kde=True, height=5, aspect=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs show anomalous distributions in the total distribution.\n",
    "<br> Probably, this is due to the technological process of processing.\n",
    "<br> For example, anomalous values may appear due to maintenance.\n",
    "<br> It is necessary to remove these anomalies, as they may affect the prediction of the model in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove these anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.dropna(inplace=True)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define functions for finding the upper and lower boundaries of the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot_line(name):\n",
    "    \n",
    "    Q1 = df_train[name].quantile(0.25)\n",
    "    Q3 = df_train[name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return Q1 - 3*IQR\n",
    "    \n",
    "    \n",
    "def top_line(name):\n",
    "    \n",
    "    Q1 = df_train[name].quantile(0.25)\n",
    "    Q3 = df_train[name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return Q3 + 3*IQR  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the flotation stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df_train['sum_rougher'].describe())\n",
    "print()\n",
    "\n",
    "index = df_train[(df_train['sum_rougher'] <= bot_line('sum_rougher')) | (df_train['sum_rougher'] >= top_line('sum_rougher'))].index\n",
    "df_train = df_train.drop(index)\n",
    "sns.displot(df_train['sum_rougher'], kde=True, height=5, aspect=1)\n",
    "plt.show()\n",
    "\n",
    "print(df_train['sum_rougher'].describe())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the first stage of cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['sum_primary'].describe())\n",
    "print()\n",
    "\n",
    "index = df_train[(df_train['sum_primary'] <= bot_line('sum_primary')) | (df_train['sum_primary'] >= top_line('sum_primary'))].index\n",
    "df_train = df_train.drop(index)\n",
    "sns.displot(df_train['sum_primary'], kde=True, height=5, aspect=1)\n",
    "plt.show()\n",
    "\n",
    "print(df_train['sum_primary'].describe())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the final stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['sum_final'].describe())\n",
    "print()\n",
    "\n",
    "index = df_train[(df_train['sum_final'] <= bot_line('sum_final')) | (df_train['sum_final'] >= top_line('sum_final'))].index\n",
    "df_train = df_train.drop(index)\n",
    "sns.displot(df_train['sum_final'], kde=True, height=5, aspect=1)\n",
    "plt.show()\n",
    "\n",
    "print(df_train['sum_final'].describe())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the description of the graphs, the average has not changed much, but the distribution has become much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to prepare two datasets.\n",
    "<br> The first to predict the share of gold after flotation.\n",
    "<br> Second for predicting the share of gold after cleaning.\n",
    "\n",
    "<br> Obviously, all the necessary NOT target features are contained in the train dataset.\n",
    "<br> For the first dataset, you need to select features with the stage `rougher` and add the target feature `rougher.output.recovery`.\n",
    "<br> For the second dataset, select all features and add the target feature `final.output.recovery`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables with the index `_r` in the name will refer to the black concentrate, those having `_f`, respectively, to the final concentrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_r = df_test.columns[13:23].to_list()\n",
    "col_r.append('rougher.output.recovery')\n",
    "col_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = df_train[col_r]\n",
    "df_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_f = df_test.columns[1:].to_list()\n",
    "col_f.append('final.output.recovery')\n",
    "col_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = df_train[col_f]\n",
    "df_f.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide the samples into sets with features and a target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_r = df_r.drop(['rougher.output.recovery'], axis=1)\n",
    "target_r = df_r['rougher.output.recovery']\n",
    "\n",
    "features_f = df_f.drop(['final.output.recovery'], axis=1)\n",
    "target_f = df_f['final.output.recovery']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide each sample into two: train, validation in the ratio `3 : 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_r, features_valid_r = train_test_split(features_r, test_size=0.25, random_state=12345)\n",
    "target_train_r, target_valid_r = train_test_split(target_r, test_size=0.25, random_state=12345)\n",
    "\n",
    "print(features_r.shape)\n",
    "print(features_train_r.shape)\n",
    "print(features_valid_r.shape)\n",
    "print(target_train_r.shape)\n",
    "print(target_valid_r.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "features_train_f, features_valid_f = train_test_split(features_f, test_size=0.25, random_state=12345)\n",
    "target_train_f, target_valid_f = train_test_split(target_f, test_size=0.25, random_state=12345)\n",
    "\n",
    "print(features_f.shape)\n",
    "print(features_train_f.shape)\n",
    "print(features_valid_f.shape)\n",
    "print(target_train_f.shape)\n",
    "print(target_valid_f.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove the target feature from the array with all features\n",
    "num_r = col_r[:len(col_r)-1]\n",
    "num_f = col_f[1:len(col_f)-1]\n",
    "\n",
    "\n",
    "scaler_r = StandardScaler()\n",
    "scaler_r.fit(features_train_r.loc[:, num_r])\n",
    "features_train_r.loc[:, num_r] = scaler_r.transform(features_train_r.loc[:, num_r])\n",
    "features_valid_r.loc[:, num_r] = scaler_r.transform(features_valid_r.loc[:, num_r])\n",
    "features_r.loc[:, num_r] = scaler_r.transform(features_r.loc[:, num_r])\n",
    "\n",
    "scaler_f = StandardScaler()\n",
    "scaler_f.fit(features_train_f.loc[:, num_f])\n",
    "features_train_f.loc[:, num_f] = scaler_f.transform(features_train_f.loc[:, num_f])\n",
    "features_valid_f.loc[:, num_f] = scaler_f.transform(features_valid_f.loc[:, num_f])\n",
    "features_f.loc[:, num_f] = scaler_f.transform(features_f.loc[:, num_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_r.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for calculating the sMAPE metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sMAPE(target, predicted):\n",
    "    \n",
    "    part = 100 * abs(target - predicted) / ((abs(target) + abs(predicted)) / 2)\n",
    "    full = part.sum() / len(target)\n",
    "    return full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for calculating model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(model, features, target):\n",
    "\n",
    "    predicted = model.predict(features)\n",
    "    predicted = pd.Series(predicted, index=target.index) \n",
    "\n",
    "    MAE = mean_absolute_error(target, predicted) ** 0.5\n",
    "    sMAPE_val = sMAPE(target, predicted)\n",
    "    \n",
    "    return (MAE, sMAPE_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Efficiency of crude concentrate enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r = LinearRegression()\n",
    "model_r.fit(features_train_r, target_train_r)\n",
    "\n",
    "results = model_results(model_r, features_valid_r, target_valid_r)\n",
    "\n",
    "print('Mean:', '{:,.2f}'.format(target_valid_r.mean()))\n",
    "print(\"MAE_valid_r:\", results[0])\n",
    "print(\"sMAPE_valid_r:\", results[1])\n",
    "print()\n",
    "\n",
    "results = model_results(model_r, features_r, target_r)\n",
    "\n",
    "print('Mean:', '{:,.2f}'.format(target_r.mean()))\n",
    "print(\"MAE_r:\", results[0])\n",
    "print(\"sMAPE_r:\", results[1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final concentrate enrichment efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_f = LinearRegression()\n",
    "model_f.fit(features_train_f, target_train_f)\n",
    "\n",
    "results = model_results(model_f, features_valid_f, target_valid_f)\n",
    "\n",
    "print('Mean:', '{:,.2f}'.format(target_valid_f.mean()))\n",
    "print(\"MAE_valid_f:\", results[0])\n",
    "print(\"sMAPE_valid_f:\", results[1])\n",
    "print()\n",
    "\n",
    "results = model_results(model_f, features_f, target_f)\n",
    "\n",
    "print('Mean:', '{:,.2f}'.format(target_f.mean()))\n",
    "print(\"MAE_f:\", results[0])\n",
    "print(\"sMAPE_r:\", results[1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Efficiency of crude concentrate enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': range(1,10)}\n",
    "\n",
    "dtr_r = GridSearchCV(estimator=DecisionTreeRegressor(random_state=12345), param_grid=param_grid, cv=5)\n",
    "dtr_r.fit(features_train_r, target_train_r)\n",
    "dtr_r.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_results(dtr_r, features_valid_r, target_valid_r)\n",
    "\n",
    "print('Mean:', '{:,.2f}'.format(target_valid_r.mean()))\n",
    "print(\"MAE_valid_r:\", results[0])\n",
    "print(\"sMAPE_valid_r:\", results[1])\n",
    "print()\n",
    "\n",
    "results = model_results(dtr_r, features_r, target_r)\n",
    "\n",
    "print('Mean:', '{:,.2f}'.format(target_r.mean()))\n",
    "print(\"MAE_r:\", results[0])\n",
    "print(\"sMAPE_r:\", results[1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final concentrate enrichment efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': range(1,10)}\n",
    "\n",
    "dtr_f = GridSearchCV(estimator=DecisionTreeRegressor(random_state=12345), param_grid=param_grid, cv=5)\n",
    "dtr_f.fit(features_train_f, target_train_f)\n",
    "dtr_f.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_results(dtr_f, features_valid_f, target_valid_f)\n",
    "\n",
    "print('Mean:', '{:,.2f}'.format(target_valid_f.mean()))\n",
    "print(\"MAE_valid_f:\", results[0])\n",
    "print(\"sMAPE_valid_f:\", results[1])\n",
    "print()\n",
    "\n",
    "results = model_results(dtr_f, features_f, target_f)\n",
    "\n",
    "print('Mean:', '{:,.2f}'.format(target_f.mean()))\n",
    "print(\"MAE_f:\", results[0])\n",
    "print(\"sMAPE_r:\", results[1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Efficiency of crude concentrate enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': range(1,10), 'max_depth': range(1,10)}\n",
    "\n",
    "rfr_r = GridSearchCV(estimator=RandomForestRegressor(random_state=12345), param_grid=param_grid, cv=5)\n",
    "rfr_r.fit(features_train_r, target_train_r)\n",
    "rfr_r.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_results(rfr_r, features_valid_r, target_valid_r)\n",
    "\n",
    "print('Mean:', '{:,.2f}'.format(target_valid_r.mean()))\n",
    "print(\"MAE_valid_r:\", results[0])\n",
    "print(\"sMAPE_valid_r:\", results[1])\n",
    "print()\n",
    "\n",
    "results = model_results(rfr_r, features_r, target_r)\n",
    "\n",
    "print('Среднее значение:', '{:,.2f}'.format(target_r.mean()))\n",
    "print(\"MAE_r:\", results[0])\n",
    "print(\"sMAPE_r:\", results[1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final concentrate enrichment efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': range(1,10), 'max_depth': range(1,10)}\n",
    "\n",
    "rfr_f = GridSearchCV(estimator=RandomForestRegressor(random_state=12345), param_grid=param_grid, cv=5)\n",
    "rfr_f.fit(features_train_f, target_train_f)\n",
    "rfr_f.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_results(rfr_f, features_valid_f, target_valid_f)\n",
    "\n",
    "print('Mean:', '{:,.2f}'.format(target_valid_f.mean()))\n",
    "print(\"MAE_valid_r:\", results[0])\n",
    "print(\"sMAPE_valid_r:\", results[1])\n",
    "print()\n",
    "\n",
    "results = model_results(rfr_f, features_f, target_f)\n",
    "\n",
    "print('Mean:', '{:,.2f}'.format(target_f.mean()))\n",
    "print(\"MAE_r:\", results[0])\n",
    "print(\"sMAPE_r:\", results[1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking models on a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the test sample with target features taken from the full sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.merge(df_full[['date','rougher.output.recovery']], on='date', how='left')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.merge(df_full[['date','final.output.recovery']], on='date', how='left')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recovery_r(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    C — share of gold in concentrate after flotation/refining;\n",
    "    F — share of gold in raw material/concentrate before flotation/refining;\n",
    "    T — share of gold in final tailings after flotation/cleaning.\n",
    "    \"\"\"\n",
    "    C = df['rougher.output.concentrate_au']\n",
    "    F = df['rougher.input.feed_au']\n",
    "    T = df['rougher.output.tail_au']\n",
    "    \n",
    "    return 100 * C * (F - T) / (F * (C - T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recovery_f(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    C — share of gold in concentrate after flotation/refining;\n",
    "    F — share of gold in raw material/concentrate before flotation/refining;\n",
    "    T — share of gold in final tailings after flotation/cleaning.\n",
    "    \"\"\"\n",
    "    C = df['final.output.concentrate_au']\n",
    "    F = df['rougher.output.concentrate_au']\n",
    "    T = df['secondary_cleaner.output.tail_au']\n",
    "    \n",
    "    return 100 * C * (F - T) / (F * (C - T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide the test sample into one that will relate to the draft concentrate and one that will relate to the final concentrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(inplace=True)\n",
    "\n",
    "df_test_r = df_test[col_r]\n",
    "df_test_f = df_test[col_f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide the sample into sets with features and a target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test_r = df_test_r.drop(['rougher.output.recovery'], axis=1)\n",
    "target_test_r = df_test_r['rougher.output.recovery']\n",
    "\n",
    "features_test_f = df_test_f.drop(['final.output.recovery'], axis=1)\n",
    "target_test_f = df_test_f['final.output.recovery']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test_r.loc[:, num_r] = scaler_r.transform(features_test_r.loc[:, num_r])\n",
    "\n",
    "features_test_f.loc[:, num_f] = scaler_f.transform(features_test_f.loc[:, num_f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking models on a test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total = 0\n",
    "\n",
    "results = model_results(model_r, features_test_r, target_test_r)\n",
    "Total += 0.25*results[1]\n",
    "\n",
    "print('Mean:', '{:,.2f}'.format(target_test_r.mean()))\n",
    "print(\"MAE_test_r:\", results[0])\n",
    "print(\"sMAPE_test_r:\", results[1])\n",
    "print()\n",
    "\n",
    "results = model_results(model_f, features_test_f, target_test_f)\n",
    "Total += 0.75*results[1]\n",
    "\n",
    "print('Mean:', '{:,.2f}'.format(target_test_f.mean()))\n",
    "print(\"MAE_test_f:\", results[0])\n",
    "print(\"sMAPE_test_f:\", results[1])\n",
    "print()\n",
    "\n",
    "print('Total sMAPE:', Total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total = 0\n",
    "\n",
    "results = model_results(dtr_r, features_test_r, target_test_r)\n",
    "Total += 0.25*results[1]\n",
    "\n",
    "print('Mean:', '{:,.2f}'.format(target_test_r.mean()))\n",
    "print(\"MAE_test_r:\", results[0])\n",
    "print(\"sMAPE_test_r:\", results[1])\n",
    "print()\n",
    "\n",
    "results = model_results(dtr_f, features_test_f, target_test_f)\n",
    "Total += 0.75*results[1]\n",
    "\n",
    "print('Mean:', '{:,.2f}'.format(target_test_f.mean()))\n",
    "print(\"MAE_test_f:\", results[0])\n",
    "print(\"sMAPE_test_f:\", results[1])\n",
    "print()\n",
    "\n",
    "print('Total sMAPE:', Total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total = 0\n",
    "\n",
    "results = model_results(rfr_r, features_test_r, target_test_r)\n",
    "Total += 0.25*results[1]\n",
    "\n",
    "print('Mean:', '{:,.2f}'.format(target_test_r.mean()))\n",
    "print(\"MAE_test_r:\", results[0])\n",
    "print(\"sMAPE_test_r:\", results[1])\n",
    "print()\n",
    "\n",
    "results = model_results(rfr_f, features_test_f, target_test_f)\n",
    "Total += 0.75*results[1]\n",
    "\n",
    "print('Mean:', '{:,.2f}'.format(target_test_f.mean()))\n",
    "print(\"MAE_test_f:\", results[0])\n",
    "print(\"sMAPE_test_f:\", results[1])\n",
    "print()\n",
    "\n",
    "print('Total sMAPE:', Total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result on the test dataset was shown by the linear regression model.\n",
    "<br> Forecast accuracy of 8.64% is quite good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "480px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
