{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import files\n",
    "2. Data processing:\n",
    "- processing of missing values,\n",
    "- processing of emissions,\n",
    "- bringing columns over time to a temporary format\n",
    "3. Based on the temperature measurement file, create a dataframe that will also contain the columns `active power`, `reactive power`, `gas`, `Bulk`, `Wire`, and for this you first need to match `Bulk` with ` Bulk_time` and `Wire` with `Wire_time`.\n",
    "<br/>Next, it is necessary to go through each line `key` and `time` of the new dataframe, depending on the column, look in the matched tables for a match on `key` with a time less than or equal to `time` and sum up all found values.\n",
    "<br/>\n",
    "<br/>Thus, you will get a dataframe with a target feature in the form of temperature and the factors that influenced it.\n",
    "\n",
    "Main goal: prediction of liquid metal temperature based on the input data from the sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `data_arc.csv` — electrode data;\n",
    "- `data_bulk.csv` - data on the supply of bulk materials (volume);\n",
    "- `data_bulk_time.csv` *—* data on the supply of bulk materials (time);\n",
    "- `data_gas.csv` — data on alloy gas purge;\n",
    "- `data_temp.csv` - temperature measurement results;\n",
    "- `data_wire.csv` - data on wire materials (volume);\n",
    "- `data_wire_time.csv` - data on wire materials (time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import copy\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from tqdm import notebook\n",
    "\n",
    "import gc\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arc = pd.read_csv('datasets/data_arc.csv')\n",
    "data_bulk = pd.read_csv('datasets/data_bulk.csv')\n",
    "data_bulk_time = pd.read_csv('datasets/data_bulk_time.csv')\n",
    "data_gas = pd.read_csv('datasets/data_gas.csv')\n",
    "data_temp = pd.read_csv('datasets/data_temp.csv')\n",
    "data_wire = pd.read_csv('datasets/data_wire.csv')\n",
    "data_wire_time = pd.read_csv('datasets/data_wire_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def print_df(df):\n",
    "    display(df)\n",
    "    df.info()\n",
    "    print('_'*120)\n",
    "    print('_'*120)\n",
    "\n",
    "print_df(data_arc)\n",
    "print_df(data_bulk)\n",
    "print_df(data_bulk_time)\n",
    "print_df(data_gas)\n",
    "print_df(data_temp)\n",
    "print_df(data_wire)\n",
    "print_df(data_wire_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the `data_temp` dataset, there are about 20% gaps in the target feature - temperature. There is nothing left but to remove these gaps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp.dropna(subset=['Temperature'], inplace=True)\n",
    "data_temp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for outliers of all signs, except for time and temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Bulk`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "\n",
    "for i in range(1,16):\n",
    "    column = 'Bulk ' + str(i)\n",
    "    print(column)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    sns.boxplot(data=data_bulk[column])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Wire`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "\n",
    "for i in range(1,10):\n",
    "    column = 'Wire ' + str(i)\n",
    "    print(column)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    sns.boxplot(data=data_wire[column])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Gas 1`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.boxplot(data=data_gas['Gas 1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's not remove `Bulk`, `Wire`, `Gas 1` emissions yet. Since the entire technological process is unknown, as well as the initial composition. If the accuracy of the model is low, then you need to go back and try to remove outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Power`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.boxplot(data=data_arc['Active power'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.boxplot(data=data_arc['Reactive power'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arc.loc[data_arc['Reactive power'] < -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arc.loc[data_arc['key'] == 2116]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Active power in the normal range, so as not to lose data, just zero the outlier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arc.loc[(data_arc['key'] == 2116) & (data_arc['Reactive power'] < -1), ['Reactive power']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arc.loc[data_arc['key'] == 2116]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #ADD8E6\">\n",
    "Delete the entire batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = data_arc.loc[data_arc['Reactive power'] < -1].index\n",
    "data_arc = data_arc.drop(index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #ADD8E6\">\n",
    "Removal of emissions `Gas 1`, `Power`. The `Bulk` and `Wire` outliers are best removed after they have matched with time signatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = data_gas['Gas 1'].quantile(0.25)\n",
    "q3 = data_gas['Gas 1'].quantile(0.75)\n",
    "irq = q3 - q1\n",
    "keys = list(data_gas.loc[(data_gas['Gas 1'] < (q1 - 1.5*irq)) | (data_gas['Gas 1'] > (q3 + 1.5*irq))]['key'].values)\n",
    "data_gas = data_gas.query('key not in @keys')\n",
    "data_gas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q1 = data_arc['Active power'].quantile(0.25)\n",
    "q3 = data_arc['Active power'].quantile(0.75)\n",
    "irq = q3 - q1\n",
    "keys = list(data_arc.loc[(data_arc['Active power'] < (q1 - 1.5*irq)) | (data_arc['Active power'] > (q3 + 1.5*irq))]['key'].values)\n",
    "data_arc = data_arc.query('key not in @keys')\n",
    "data_arc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace missing `Bulk` and `Wire` values with zeros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bulk.fillna(0, inplace=True)\n",
    "data_wire.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction of features to the format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's bring all the signs to the appropriate format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arc['Start of arc heating'] = pd.to_datetime(data_arc['Start of arc heating'], format='%Y-%m-%dT%H:%M:%S')\n",
    "data_arc['End of arc heating'] = pd.to_datetime(data_arc['End of arc heating'], format='%Y-%m-%dT%H:%M:%S')\n",
    "data_arc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,16):\n",
    "    column = 'Bulk ' + str(i)\n",
    "    data_bulk_time[column] = pd.to_datetime(data_bulk_time[column], format='%Y-%m-%dT%H:%M:%S')\n",
    "data_bulk_time.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp['Measurement time'] = pd.to_datetime(data_temp['Measurement time'], format='%Y-%m-%dT%H:%M:%S')\n",
    "data_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    column = 'Wire ' + str(i)\n",
    "    data_wire_time[column] = pd.to_datetime(data_wire_time[column], format='%Y-%m-%dT%H:%M:%S')\n",
    "data_wire_time.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking temporal features for outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the time series of datasets for outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Bulk`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "\n",
    "for i in range(1,16):\n",
    "    column = 'Bulk ' + str(i)\n",
    "    print(column)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    sns.scatterplot(x = data_bulk_time[column], y=data_bulk_time['key'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Wire`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "\n",
    "for i in range(1,10):\n",
    "    column = 'Wire ' + str(i)\n",
    "    print(column)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    sns.scatterplot(x = data_wire_time[column], y=data_wire_time['key'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Heating`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = copy.deepcopy(data_arc[['key','Start of arc heating']])\n",
    "df1['Type'] = 'Start of heating'\n",
    "df1.rename(columns={'Start of arc heating':'Heating'},inplace=True)\n",
    "df2 = copy.deepcopy(data_arc[['key','End of arc heating']])\n",
    "df2['Type'] = 'End of heating'\n",
    "df2.rename(columns={'End of arc heating':'Heating'},inplace=True)\n",
    "df = pd.concat([df1,df2], ignore_index=True,join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x = 'key', y = 'Heating', color='Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df1,df2,df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No outliers detected over time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check temperature signs for outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for temperature spikes in each dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.boxplot(data=data_temp['Temperature'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's not remove outliers yet. Since the entire technological process is unknown, as well as the initial composition. If the accuracy of the model is low, then you need to go back and try to remove outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #ADD8E6\">\n",
    "Removing temperature outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is best to remove temperature outliers in the final dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a final dataset for training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match datasets with `Bulk` and `Wire`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk = data_bulk.join(data_bulk_time,rsuffix='_time').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['key']\n",
    "for i in range(1,16):\n",
    "    name = 'Bulk ' + str(i)\n",
    "    col.append(name)\n",
    "    name = 'Bulk ' + str(i) + '_time'\n",
    "    col.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_bulk = df_bulk[col]\n",
    "df_bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wire = data_wire.join(data_wire_time,rsuffix='_time').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['key']\n",
    "for i in range(1,10):\n",
    "    name = 'Wire ' + str(i)\n",
    "    col.append(name)\n",
    "    name = 'Wire ' + str(i) + '_time'\n",
    "    col.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_wire = df_wire[col]\n",
    "df_wire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #ADD8E6\">\n",
    "Removing outliers `Bulk`, `Wire`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_bulk.info())\n",
    "display(df_wire.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bulk**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing a line with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,16):\n",
    "#     col = 'Bulk ' + str(i)\n",
    "#     q1 = df_bulk[col].quantile(0.25)\n",
    "#     q3 = df_bulk[col].quantile(0.75)\n",
    "#     irq = q3 - q1\n",
    "#     index = df_bulk.loc[(df_bulk[col] < (q1 - 1.5*irq)) | (df_bulk[col] > (q3 + 1.5*irq))].index\n",
    "#     df_bulk = df_bulk.drop(index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing outliers with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,16):\n",
    "#     col = 'Bulk ' + str(i)\n",
    "#     q1 = df_bulk[col].quantile(0.25)\n",
    "#     q3 = df_bulk[col].quantile(0.75)\n",
    "#     irq = q3 - q1\n",
    "#     df_bulk.loc[(df_bulk[col] < (q1 - 1.5*irq)) | (df_bulk[col] > (q3 + 1.5*irq)), col] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting all key where there is at least one outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = []\n",
    "for i in range(1,16):\n",
    "    col = 'Bulk ' + str(i)\n",
    "    q1 = df_bulk[col].quantile(0.25)\n",
    "    q3 = df_bulk[col].quantile(0.75)\n",
    "    irq = q3 - q1\n",
    "    keys.append(list(df_bulk.loc[(df_bulk[col] < (q1 - 1.5*irq)) | (df_bulk[col] > (q3 + 1.5*irq))]['key'].values))\n",
    "\n",
    "new_keys = list(chain.from_iterable(keys))\n",
    "\n",
    "\n",
    "df_bulk = df_bulk.query('key not in @new_keys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wire**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing a line with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,10):\n",
    "#     col = 'Wire ' + str(i)\n",
    "#     q1 = df_wire[col].quantile(0.25)\n",
    "#     q3 = df_wire[col].quantile(0.75)\n",
    "#     irq = q3 - q1\n",
    "#     index = df_wire.loc[(df_wire[col] < (q1 - 1.5*irq)) | (df_wire[col] > (q3 + 1.5*irq))].index\n",
    "#     df_wire = df_wire.drop(index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing outliers with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,10):\n",
    "#     col = 'Wire ' + str(i)\n",
    "#     q1 = df_wire[col].quantile(0.25)\n",
    "#     q3 = df_wire[col].quantile(0.75)\n",
    "#     irq = q3 - q1\n",
    "#     df_wire.loc[(df_wire[col] < (q1 - 1.5*irq)) | (df_wire[col] > (q3 + 1.5*irq)), col] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting all key where there is at least one outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = []\n",
    "for i in range(1,10):\n",
    "    col = 'Wire ' + str(i)\n",
    "    q1 = df_wire[col].quantile(0.25)\n",
    "    q3 = df_wire[col].quantile(0.75)\n",
    "    irq = q3 - q1\n",
    "    keys.append(list(df_wire.loc[(df_wire[col] < (q1 - 1.5*irq)) | (df_wire[col] > (q3 + 1.5*irq))]['key'].values))\n",
    "\n",
    "new_keys = list(chain.from_iterable(keys))\n",
    "\n",
    "df_wire = df_wire.query('key not in @new_keys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_bulk.info())\n",
    "display(df_wire.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the dataset with all the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full = copy.deepcopy(data_temp)\n",
    "full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['gas'] = 0\n",
    "full['AP'] = 0\n",
    "full['RP'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,16):\n",
    "    column = 'Bulk ' + str(i)\n",
    "    full[column] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    column = 'Wire ' + str(i)\n",
    "    full[column] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_ap(row):\n",
    "    v = data_arc['Active power'].loc[(data_arc['key'] == row['key'])].sum()\n",
    "    return v\n",
    "\n",
    "full['AP'] = full.apply(func_ap, axis=1)\n",
    "\n",
    "def func_rp(row):\n",
    "    v = data_arc['Reactive power'].loc[(data_arc['key'] == row['key'])].sum()\n",
    "    return v\n",
    "\n",
    "full['RP'] = full.apply(func_rp, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_gas(row):\n",
    "    v = data_gas['Gas 1'].loc[(data_gas['key'] == row['key'])].sum()\n",
    "    return v\n",
    "\n",
    "full['gas'] = full.apply(func_gas, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def func_bulk(row,col):\n",
    "    time_col = col + '_time'\n",
    "    v = df_bulk[col].loc[(df_bulk['key'] == row['key']) & (df_bulk[time_col] <= row['Measurement time'])].sum()\n",
    "    return v\n",
    "\n",
    "for i in notebook.tqdm(range(1,16)):\n",
    "    col = 'Bulk ' + str(i) \n",
    "    full[col] = full.apply(lambda x: func_bulk(x, col), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_wire(row,col):\n",
    "    time_col = col + '_time'\n",
    "    v = df_wire[col].loc[(df_wire['key'] == row['key']) & (df_wire[time_col] <= row['Measurement time'])].sum()\n",
    "    return v\n",
    "\n",
    "for i in notebook.tqdm(range(1,10)):\n",
    "    col = 'Wire ' + str(i) \n",
    "    full[col] = full.apply(lambda x: func_wire(x, col), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In each batch, it is necessary to leave only the last measurement, and we will train the model on it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = copy.deepcopy(full)\n",
    "n.sort_values(by=['key','Measurement time'], ascending=True,inplace=True)\n",
    "n.drop_duplicates(subset=['key'], keep='first', inplace=True)\n",
    "n.reset_index(drop=True,inplace=True)\n",
    "n = n[['key','Temperature']]\n",
    "n.rename(columns={'Temperature':'Initial temperature'},inplace=True)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = copy.deepcopy(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.sort_values(by=['key','Measurement time'], ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.drop_duplicates(subset=['key'], keep='last', inplace=True)\n",
    "f.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f.merge(n,how='left',on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div style=\"background: #ADD8E6\">\n",
    "Removing rows where the end temperature is equal to the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = f.loc[f['Initial temperature'] == f['Temperature']].index\n",
    "f = f.drop(index).reset_index(drop=True)\n",
    "f.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #ADD8E6\">\n",
    "Removing rows where there is no final temperature measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_ds = data_arc[['key','End of arc heating']].sort_values(by=['End of arc heating'])\n",
    "semi_ds.drop_duplicates(subset=['key'], keep='last', inplace=True)\n",
    "semi_ds.reset_index(drop=True,inplace=True)\n",
    "semi_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = f.merge(semi_ds,how='left',on='key')\n",
    "f.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = f.loc[f['Measurement time'] < f['End of arc heating']].index\n",
    "f = f.drop(index).reset_index(drop=True)\n",
    "f.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #ADD8E6\">\n",
    "Removing temperature outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = f['Temperature'].quantile(0.25)\n",
    "q3 = f['Temperature'].quantile(0.75)\n",
    "irq = q3 - q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = f.loc[(f['Temperature'] < (q1 - 1.5*irq)) | (f['Temperature'] > (q3 + 1.5*irq))].index\n",
    "f = f.drop(index).reset_index(drop=True)\n",
    "f.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = f['Initial temperature'].quantile(0.25)\n",
    "q3 = f['Initial temperature'].quantile(0.75)\n",
    "irq = q3 - q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = f.loc[(f['Initial temperature'] < (q1 - 1.5*irq)) | (f['Initial temperature'] > (q3 + 1.5*irq))].index\n",
    "f = f.drop(index).reset_index(drop=True)\n",
    "f.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.drop(['Measurement time','key','End of arc heating'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del data_arc, data_bulk, data_bulk_time, data_gas, data_temp, data_wire, data_wire_time, df_bulk, df_wire, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = f.corr()\n",
    "fig = px.imshow(corr)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in list(corr.columns.unique()):\n",
    "    print(col)\n",
    "    display(corr.loc[(corr[col] < 1) & (corr[col] >= 0.6),col])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the following features due to the strong correlation: `RP`,`Bulk 7`,`Wire 4`,`Wire 8`,`Bulk 15`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.drop(['RP', 'Bulk 14', 'Bulk 15'], inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = f.corr()\n",
    "for col in list(corr.columns.unique()):\n",
    "    print(col)\n",
    "    display(corr.loc[(corr[col] < 1) & (corr[col] >= 0.6),col])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building temperature prediction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's split the sample into sets with features and a target feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = f.drop(['Temperature'], axis=1)\n",
    "target = f['Temperature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_valid = train_test_split(features, test_size=0.20, random_state=12345)\n",
    "features_train, features_test = train_test_split(features_train, test_size=0.25, random_state=12345)\n",
    "\n",
    "target_train, target_valid = train_test_split(target, test_size=0.20, random_state=12345)\n",
    "target_train, target_test = train_test_split(target_train, test_size=0.25, random_state=12345)\n",
    "\n",
    "print(features.shape)\n",
    "print(target.shape)\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train)\n",
    "features_train = scaler.transform(features_train)\n",
    "features_valid = scaler.transform(features_valid)\n",
    "features_test = scaler.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(features_train, target_train)\n",
    "predictions = model_lr.predict(features_valid)\n",
    "mae = mean_absolute_error(target_valid, predictions)\n",
    "print('MAE Linear Regression:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {'max_depth': range(1,100,2)}\n",
    "\n",
    "dtr = GridSearchCV(estimator=DecisionTreeRegressor(random_state=12345), param_grid=param_grid, cv=5,scoring='neg_mean_absolute_error')\n",
    "dtr.fit(features_train, target_train)\n",
    "dtr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dtr.predict(features_valid)\n",
    "mae = mean_absolute_error(target_valid, predictions)\n",
    "print('MAE decision tree:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {'n_estimators': range(1,150,3), 'max_depth': range(1,150,3)}\n",
    "\n",
    "rfr = GridSearchCV(estimator=RandomForestRegressor(random_state=12345), param_grid=param_grid, cv=5,verbose=2,scoring='neg_mean_absolute_error')\n",
    "rfr.fit(features_train, target_train)\n",
    "rfr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfr.predict(features_valid)\n",
    "mae = mean_absolute_error(target_valid, predictions)\n",
    "print('MAE Random Forest:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l1',\n",
    "    'metric': 'mae',\n",
    "    'learning_rate': 0.005,\n",
    "    'verbose': 0,\n",
    "    \"max_depth\": 100,\n",
    "    \"num_iterations\": 20000,\n",
    "    \"n_estimators\": 5000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbm = lgb.LGBMRegressor(**hyper_params)\n",
    "gbm.fit(features_train, target_train, \n",
    "        eval_set=[(features_valid, target_valid)],\n",
    "        eval_metric='mae', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE LightGBM:', gbm.best_score_['valid_0']['l1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(dtr.best_estimator_.feature_importances_,\n",
    "                                   index = features.columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rfr.best_estimator_.feature_importances_,\n",
    "                                   index = features.columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(gbm.feature_importances_,\n",
    "                                   index = features.columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking models on a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_lr.predict(features_test)\n",
    "mae = mean_absolute_error(target_test, predictions)\n",
    "print('MAE Linear Regression:', mae)\n",
    "\n",
    "predictions = dtr.predict(features_test)\n",
    "mae = mean_absolute_error(target_test, predictions)\n",
    "print('MAE decision tree:', mae)\n",
    "\n",
    "predictions = rfr.predict(features_test)\n",
    "mae = mean_absolute_error(target_test, predictions)\n",
    "print('MAE Random Forest:', mae)\n",
    "\n",
    "predictions = gbm.predict(features_test)\n",
    "mae = mean_absolute_error(target_test, predictions)\n",
    "print('MAE LightGBM:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score - Random Forest : 5.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "107.988px",
    "width": "262.5px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "823.938px",
    "left": "1377px",
    "right": "20px",
    "top": "139px",
    "width": "440.469px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
